---
title: "Assignment 3"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# install requisite packages
# install.packages(tidyverse)
# install.packages(rvest)
# install.packages(RColorBrewer)
# install.packages(knitr)
# install.packages(here)

# save packages to library
library(tidyverse)
library(rvest)
library(RColorBrewer)
library(knitr)
library(here)

# save data as object
data <- read.csv(here("Assignment 3/GOTV_Experiment.csv"))
```

**Several factors complicate the analysis of this particular experiment. First, the probability of being randomly assigned to treatment was different for urban and non-urban areas. Second, some people assigned to treatment did not receive the treatment. And third, we are unable to observe turnout for some of the subjects. See the README file for more details.** 
 
**a) Calculate the mean value of turnout for people who did and did not receive the treatment, and interpret the implied effect of get-out-the-vote interventions on turnout. Think about the likely biases that arise from the three complications listed above. If you had to guess, would you say that you are likely over- or under-estimating the average effect with this analysis? Explain your answer.**

```{r implied effect}
# find average turnout of those who received the treatment
mean_turnout_t1 <- data %>% 
  filter(successfultreatment == 1) %>% 
  filter(is.na(turnout) != 1) %>% 
  summarise(mean = mean(turnout))
mean_turnout_t1

# find average turnout of those who did not receive the treatment
mean_turnout_t0 <- data %>% 
  filter(successfultreatment == 0) %>% 
  filter(is.na(turnout) != 1) %>% 
  summarise(mean = mean(turnout))
mean_turnout_t0

# estimate the implied effect of treatment
implied_effect <- mean_turnout_t1 - mean_turnout_t0
implied_effect
```

The mean value of turnout (rounded to the nearest thousandth) for people hwo did and did not receive the treatment are .594 and .474, respectively, and the implied effect of the treatment is the difference between these two averages. From this estimate, the implied effect of get-out-the-vote interventions on turnaround is .119. That is, the get-out-the-vote intervention is interpreted to have caused an 11.9% increase in turnout from between the treatment and control groups. 

This number is likely an overestimate of the average effect of the treatment. The three complications to the experiment--differing probabilities of assignment between urban and non-urban areas, presence of noncompliance, and attrition in the sample--all create baseline differences between our treatment and control groups, which biases our estimate of the average effect in a positive directions. As a result, the number found above likely overestimates the magnitude of the effect of get-out-the-vote interventions on turnout. 

The first complication makes living in an urban area a confounder because residential location influences likelihood of treatment and outcome above and beyond random assignment of treatment into one of those states. We can verify this by finding comparing a) probabilities of urbanites and non-urbanites of being assigned into the treatment or control group and b) the average likelihood of these two groups to turnout in the control group. 

```{r urban confounder}
# find proprotion of urbanites in the sample
prop_urban <- data %>% 
  filter(urban == 1) %>% 
  count()/50000
prop_urban  

# find proportion of non-urbanites in the sample
prop_nonurban <- data %>% 
  filter(urban == 0) %>% 
  count()/50000
prop_nonurban

# find proportion of urbanites in the treatment group
prop_urban_treat <- data %>% 
  filter(urban == 1 & treatmentattempt == 1) %>% 
  count()/25099
prop_urban_treat 

# find proportion of urbanites in the control group
prop_urban_control <- data %>% 
  filter(urban == 1 & treatmentattempt == 0) %>% 
  count()/25099
prop_urban_control 

# find proportion of non-urbanites in the treatment group
prop_nonurban_treat <- data %>% 
  filter(urban == 0 & treatmentattempt == 1) %>% 
  count()/25099
prop_nonurban_treat 

# find proportion of non-urbanites in the control group
prop_nonurban_control <- data %>% 
  filter(urban == 0 & treatmentattempt == 0) %>% 
  count()/25099
prop_nonurban_control

```

From the analysis above, urbanites and non-urbanites represent roughly half of the sample, yet they both
groups not equally present in similar proprotions within the control and sample. Given that an 
observation lived in an urban area, the probability of being assigned to the treatment and control 
groups were .199 and .792, respectively, while the same of an observation living outside an urban area 
was .801 and .201, respectively. Therefore, urbanites are substantially underrepresented in the
treatment group overrepresented in the control group. 

Now, to figure out whether being in an urban area is associated with greater likelihood to vote, we can compare turnout between urbanites and non-urbanites in the control.

```{r compare turnout}
# find proportion of urbanites in control who voted
control_urban_turnout <- data %>% 
  filter(urban == 1 & treatmentattempt == 0 & turnout == 1) %>% 
  count()/19868
control_urban_turnout

# find proportion of non-urbanites in control who voted
control_nonurban_turnout <- data %>% 
  filter(urban == 0 & treatmentattempt == 0 & turnout == 1) %>% 
  count()/5033
control_nonurban_turnout

# find average difference in likelihood to turnout
turnout_difference <- control_urban_turnout - control_nonurban_turnout
turnout_difference
```

After conducting this comparison, it clear is that non-urban residents in the control group were more
likely to turn out than urban residents. More specifically, the average difference in turnout was
-.0611, or urbanites in the control were 6.11% less likely to turnout absent the intervention. Normally,
this difference wouldn't be a problem because randomization would guarantee that, in expectation,
such differences would be spread evenly on average between the treatment and control. 

However, assignment was not random. Being an urbanite made a given observation substantially less likely
to be assigned to the treatment group. In addition, urbanites are less likely to turnout. The
combination of these facts means there are baseline differences present; the experiment is not comparing
apples-to-oranges. 

As a result, "urban" is a confounder, which results in the implied effect of
get-out-the-vote interventions being overestimated. This bias occurs because the sign of the 
confounder's influence on treatment and likelihood are both negative. Living in an urban area means 
observations in that group were both less likely to be in the treatment group and less likely to vote,
which biases our results toward an overestimation of the result.

The second complication is the presence of noncompliers. Not all people assigned to treatment were
successfully treated. This is hard to empirically assess because comparing the turnout of noncompliers
(who where assigned to treatment) and the same of the control group is not apples-to-apples. 

However, we can reason that noncompliers are less likely to turnout than compliers. Perhaps 
noncompliers, on  average, are less friendly or community-oriented and so are less liley to answer their
door when they hearing a political canvasser knocking. I would wager that these characteristics are 
correlated with lower probabilities of turnout. 

If this assumption holds, then the naive implied estimate of get-out-the-vote operations might be 
an overestimation because noncompliers, who we assume are less likley to turnout, are present in the 
control group but not the treatment. Therefore, baseline differences are present, and the resulting bias
bias is positive because being a noncomplier reduces the probability that observations in this group are
assigned to the treatment and will turnout. 

In other words, noncompliance is a confounder, and the sign of its influence upon both treatment and 
the outcome are negative, which means it would positively bias our naive estimate. Noncompliance results
in an overestimation of the effect of get-out-the-vote interventions. 

The third complication is attrition. Many of the observations in both the control and the treatment 
groups attrited from the sample, that is, whether they voted could not be ascertained perhaps because
they moved out of state, died, or mysteriously vanished. Crucially, whether or not this attrition biases
the implied effect of get-out-the-vote interventions dependson the nature of the attrition. If attrition
occured at random (i.e., is unrelated to the treatment of potential outcome), then attrition does not
bias our estimate (just reduces the sample size). 

I do not think there are strong reasons to believe attrition is systematically treatment or outcome of
interest. The hypothetical reasons enumerated above are rather idiosyncratic; assignment to the
treatment group is hardlly likely to make a participant move out of state. As such, I would wager that
attrition was random in nature and therefore does not bias our the implied effect of get-out-the-vote
interventions. 

Briefly, we can confirm this hypothesis by testing whether rates of attrition were significantly higher
in either the treatment or control group. 

```{r attrition}
# find proportion of attrited sample assigned to treatment
prop_attrited_treat <- data %>% 
  filter(treatmentattempt == 1 & is.na(turnout)) %>% 
  count()/25099
prop_attrited_treat

# find proportion of attrited sample assigned to control
prop_attrited_control <- data %>% 
  filter(treatmentattempt == 0 & is.na(turnout)) %>% 
  count()/24901
prop_attrited_control

# find the difference of average attrition between treatment and control
attrition_diff <- prop_attrited_treat - prop_attrited_control
attrition_diff
```

From the analysis above, it is likely that attrition was random and unrelated to assignment to treatment
or control groups. The difference in average attrition between the two groups, at less than .0001, is
minuscule. Assuming a null hypothesis of no rleationship between attrition and assignment, even without
formal calculation of a p-value, it is very unlikely that the null could be rejected. Thus, we have
strong evidence that attrition was random, which mean it does not contribute to baseline differences
between the two groups. 

In conclusion, it is likely that this analysis overestimates the average effect of get-out-the-vote
efforts. While attribution likely does not contribute to bias, the other two complications, non-random
assignment and the presence of noncompliance, both bias the estimate in a positive direction, resulting
in an over-estimate of the treatment's effect. 

**b) Using the lessons from Chapter 10, try to account for the fact that probability of treatment between urban and non-urban areas. How did you estimate your change? Why?**

```{r control urban confounder}
# regress turnout on treatment
regression <- lm(data = data, turnout ~ successfultreatment)
summary(regression)

# regress turnout on treatment and urban
regression_test <- lm(data = data, turnout ~ successfultreatment + urban)
summary(regression_test)

```

I tried accounting for the bias introduced by the divergent probability of treatment between urban and non-urban areas by regressing turnout on both treatment and an "urban" dummy variable, which is 1 when an observation lives in an urban area and 0 when they live in a non-urban area. 

Essentially, I am controlling for the bias introduced by this confounder.
Including an urban variable in the regression incorporates information about
the effect of this confounder upon the outcome. This improves the accuracy of
the estimated relationship between the treatment and the outcome by holding the
urban variable constant. Conceptually, when controlling for urban residence, 
the estimated effect of the treatment becomes a weighted average of the
relationship between treatment and outcome of interest for urbanites and
non-urbanites.

My estimate decreased by from .119 to .104, for a decrease of .015. This likely
occurred because urban residence makes an individual less likely to both turnout
and be successfully treated, and the original (biased) estimate inaccurately
included some of this influence within the implied effect of treatment on
turnout. Making this effect explicit, therefore, reduces the reported causal
relationship between treatment and turnout.

**c) Using the lessons from the chapter, let’s try to account for noncompliance. First, try to estimate the intent-to-treat effect (reduced form) and the compliance rate (first stage). Now divide the former by the latter to estimate the compiler average treatment effect.**

It would be dangerous to estimate the effect of the treatment without accounting for noncompliance and 
non-random assignment. To do so, I will estimate a separate complier average treatment effect (CATE)
for urbanites and non-urbanites in the sample. Finding the CATE uses instrumental variables to account for noncompliance and estimating separate CATEs mitigates the bias produced by non-random assignment. 

In practice, I will find the CATE by first identifying the "intent-to-treat" (ITT) effect, the average difference in turnout between those assigned to treatment and control, for both groups. Then I will find the proportion of compliers and divide the ITT effect by that proprortion to get an unbiased estimate of the CATE. This will be the "Wald Estimator" for both urban and non-urban groups. 

Considering the urban and non-urban groups separately is possible because the sample size is adequately large. The smallest subset, urbanites in the treatment group and non-urbanites in the control, still have roughly 5,000 observations. That number is sufficient to let me compare treatment the control and treatment groups of urban and non-urban residents. 

Note: I choose to drop those observations for whom we do not know their turnout. Dropping here is justified because, as dicussed above, attrition was likely random and unrelated to treatment status. 

```{r ITT}
# find the intent-to-treat effect for both groups
# urban first - estimate number of non-attrited urbanites in treatment group
n_urban_treatment <- data %>% 
  filter(urban == 1 & treatmentattempt == 1 & is.na(turnout) != 1) %>% 
  count()

# estimate number of non-attrited urbanites in control group
n_urban_control <- data %>% 
  filter(urban == 1 & treatmentattempt == 0 & is.na(turnout) != 1) %>% 
  count()

# find average turnout for control and treatment groups
urban_turnout_treatment <- data %>% 
  filter(urban == 1 & treatmentattempt == 1 & turnout == 1) %>% 
  count()/n_urban_treatment

urban_turnout_control <- data %>% 
  filter(urban == 1 & treatmentattempt == 0 & turnout == 1) %>% 
  count()/n_urban_control

# find the average difference in turnout for treatment and control groups
ITT_urban <- urban_turnout_treatment - urban_turnout_control
ITT_urban

# non-urban second - estimate number of non-attrited non-urban residents in treatment group
n_nonurban_treatment <- data %>% 
  filter(urban == 0 & treatmentattempt == 1 & is.na(turnout) != 1) %>% 
  count()

# estimate number of non-attrited non-urban residents in treatment group
n_nonurban_control <- data %>% 
  filter(urban == 0 & treatmentattempt == 0 & is.na(turnout) != 1) %>% 
  count()

# find average turnout for control and treatment groups
nonurban_turnout_treatment <- data %>% 
  filter(urban == 0 & treatmentattempt == 1 & turnout == 1) %>% 
  count()/n_nonurban_treatment

nonurban_turnout_control <- data %>% 
  filter(urban == 0 & treatmentattempt == 0 & turnout == 1) %>% 
  count()/n_nonurban_control

# find the average difference in turnout for treatment and control groups
ITT_nonurban <- nonurban_turnout_treatment - nonurban_turnout_control
ITT_nonurban

```

The estimated intent-to-treat effects are .041 and .033 for urban and non-areas, respectively, which describe the average difference in turnout between treatment and control gorups for urban and non-urban areas. Next I estimate the proportion of compliers in each group.

```{r prop compliers}
# find the proportion of compliers for both groups
# urban first - estimate proportion of compliers and always-takers in treatment group
urban_compliers <- data %>% 
  filter(urban == 1 & treatmentattempt == 1 & successfultreatment == 1) %>% 
  count()/n_urban_treatment
urban_compliers

# non-urban second - estimate proportion of compliers and always-takers in treatment group
nonurban_compliers <- data %>% 
  filter(urban == 0 & treatmentattempt == 1 & turnout == 1) %>% 
  count()/n_nonurban_treatment
nonurban_compliers

```


The numbers above imply that the proportion of compliers for urban and non-urban areas are .753 and .566, respectively. Now we implement the Wald Estimator for both groups to find an unbiased estimate of their CATEs. 

```{r prop compliers}
# find the proportion of compliers for both groups
# urban first - estimate proportion of compliers and always-takers in treatment group
urban_compliers <- data %>% 
  filter(urban == 1 & treatmentattempt == 1 & successfultreatment == 1) %>% 
  count()/n_urban_treatment
urban_compliers

# non-urban second - estimate proportion of compliers and always-takers in treatment group
nonurban_compliers <- data %>% 
  filter(urban == 0 & treatmentattempt == 1 & turnout == 1) %>% 
  count()/n_nonurban_treatment
nonurban_compliers

```

```{r wald}
# implement the Wald Estimator by dividing the ITT by proportion of compliers
# urban first - divide the ITT by proportion of urban compliers
urban_CATE <- ITT_urban/urban_compliers
urban_CATE

# non-urban second - divide the ITT by proportion of non-urban compliers
nonurban_CATE <- ITT_nonurban/nonurban_compliers
nonurban_CATE

```

After implementing the Wald Estimator, we find unbiased estimates of the CATE for both urban and non-urban areas, which are .055 and .058, respectively. We now find an overall CATE for get-out-the-vote interventions by taking an average, weighted by which area had more variation in the treatment group. Since there was equal roughly variation in the treatment group for urban and non-urban voters, we take a simple average of the two. 

```{r overall wald}
# average the two unbiased esitmates of CATE
final_CATE <- (urban_CATE + nonurban_CATE)/2
final_CATE

```

The final, unbaised estimate of the CATE for get-out-the-vote interventions is 0.0561, that is, compliers were 5.6% more likely to turnout after being assigned to the treatment group. 

**d) Think about the attrition problem. What are you implicitly assuming if you just drop the subjects for whom we don’t observe their turnout? Let’s see how their estimates change under different assumptions. Estimate the compiler average treatment effect assuming that none of the subjects who attrited would have voted. What would your estimate be under the worst-case scenario for the effectiveness of GOTV? What about the best-case scenario?**
