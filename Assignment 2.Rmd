---
title: "Assignment 2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Quantitative Methods in Public Policy Assignment 2

Before moving into the body of this assignment, I will install requisite packages and save our data of interest as an object. I also edit a few options to expand the size of resulting figures. 

```{r packages and data}
# configure options for figure aesthetics
knitr::opts_chunk$set(echo = TRUE, fig.width = 12, fig.height = 8)

# install requisite packages
# install.packages(tidyverse)
# install.packages(rvest)
# install.packages(RColorBrewer)
# install.packages(tidytext)
# install.packages(knitr)
# install.packages(downloader)
# install.packages(here)

# save packages to library
library(tidyverse)
library(rvest)
library(RColorBrewer)
library(tidytext)
library(knitr)
library(downloader)
library(here)

# the data analyzed in this assignment concerns the correlation between years of education and earnings of men who were aged between 41 and 50 years. The data can be downloaded via this link. Below is an explainer of the data taken from the read.me.

# "Angrist and Krueger obtained their data from the Integrated Public Use
# Microdata Series from the 1980 U.S. Census.

# The study specifically focused on men born between 1930 and 1939, so they
# were 41-50 years old at the time of data collection.

# Each row corresponds to a large group of men with the same level of
# schooling.

# The variable "schooling" indicates the years of schooling for each group.
# 12 corresponds with high school completion, and 16 corresponds with 
# college completion.

# The variable "earnings" indicates the average annual earnings (in 1980
# U.S. dollars) for the men in each group."

# save the data as an object
schooling_data <- read.csv(here("Files for Data Exercises/SchoolingEarnings.csv"))
  # note here() is taken from the here package. It makes code reproducible across different users and
  # computer systems by creating from the working directory to the file's location. 
  # For instance, running "here("Files for Data Exercises/SchoolingEarnings.csv")" in my console returns
  # "/Users/zanderarnao/Desktop/github projects/Quantitative-Methods/Files for Data
  # Exercises/SchoolingEarnings.csv". 

```

With the data saved and options initialized, we now move into the required questions.

**5.1) Run a regression with earnings as the dependent variable and schooling as the sole independent variable. Interpret the coefficients.** 

Below I run an ordinary least squares regression on the schooling data, resulting in a line of best fit. Here schooling serves as the independent variable and earnings as the dependent. I provide a table with the relevant regression parameters, the regression coefficient (beta) and the intercept (alpha). I visualize the regression line against a scatter plot of the data for helpful reference. 

```{r problem 5.1}

# fit a regression line to the schooling data and show a result with regression
regression <- lm(data = schooling_data, earnings ~ schooling)
summary(regression)

# visualize the regression line in a scatter plot with a regression line
schooling_data %>% 
  ggplot(aes(x = schooling, y = earnings)) + 
  geom_point() + 
  geom_smooth(color = "purple", method = lm) + 
    labs(
    title = "Association between years of schooling and earned income",
    x = "Years of Schooling",
    y = "Earnings") + 
  scale_fill_brewer(palette = "Set3") +
  theme_bw()

```

The regression coefficient and intercept are given in the table above. Beta is 1.16185, which is the slope of the regression line. Its sign is positive, which tells us that there is a positive correlation between years of schooling and earnings, i.e., that, on average, an increase in one variable is associated with an increase in the other.

The specific magnitude of the correlation 1.16185, which means that the middle aged men in our data, each additional year of schooling corresponds, on average, to an increase in income by approximately $1,161.85 (1980 dollars).

Alpha is 8.79853, which tells us that the men in this cohort who received no years of schooling earned, on average, about $8,798.53 in 1980 dollars. 

**5.2) Suppose you wanted a parsimonious way to predict earnings using only years of schooling. What would you do?**

**5.3) Let’s dig more deeply into whether the relationship between earning and schooling is approximately linear.**

**a) Start by making a scatter plot. Then plot the predicted values from your regression along with the raw data points, as we did in chapter 2. Does the regression line look like it’s fitting the data well?**

**b) Now run a fourth-order polynomial regression (i.e., including schooling, schooling squared, schooling to the third, and schooling to the fourth). Do those predictions meaningfully differ from the predictions coming from the linear regression?**

**c) Now run different regressions for some different ranges of schooling. Do those lines look meaningfully different from the predictions you get from a single regression including all the data?**

**d) Does all this make you think the simple linear approach was reasonable or unreasonable?**

**5.4) Similar to what we did with age and voter turnout, conduct some out-of-sample tests to evaluate your prediction strategy. Using only data from those with twelve years of schooling or less, see how well your different strategies from question 3 perform when predicting earnings for those with more than twelve years of schooling.**

**5.5). Drop one observation, run a regression to try to predict the outcome for that missing observation, and see how far you were. Repeat this for each observation in the data set (you should be able to do this with a loop) and average your errors. Try different strategies to see which one gives you the best out-of-sample predictions.**


```{r code}

# configure figures for aesthetics
knitr::opts_chunk$set(echo = TRUE, fig.width = 12, fig.height = 8)

# install requisite packages
# install.packages(tidyverse)
# install.packages(rvest)
# install.packages(RColorBrewer)
# install.packages(tidytext)
# install.packages(knitr)
# install.packages(downloader)
# install.packages(here)

# save requisite packages to library
library(tidyverse)
library(rvest)
library(RColorBrewer)
library(tidytext)
library(knitr)
library(downloader)
library(here)

# show explainer of data for future reference (from the associated read_me)
# "Angrist and Krueger obtained their data from the Integrated Public Use
# Microdata Series from the 1980 U.S. Census.

# The study specifically focused on men born between 1930 and 1939, so they
# were 41-50 years old at the time of data collection.

# Each row corresponds to a large group of men with the same level of
# schooling.

# The variable "schooling" indicates the years of schooling for each group.
# 12 corresponds with high school completion, and 16 corresponds with 
# college completion.

# The variable "earnings" indicates the average annual earnings (in 1980
# U.S. dollars) for the men in each group."

# save data to variable
schooling_data <- read.csv(here("Files for Data Exercises/SchoolingEarnings.csv"))
  # note here() removes the need to set a working directory by X

# fit a regression line
regression <- lm(data = schooling_data, earnings ~ schooling)
summary(regression)

# visualize data in a scatter plot with a regression line
schooling_data %>% 
  ggplot(aes(x = schooling, y = earnings)) + 
  geom_point() + 
  geom_smooth(method = lm)

# fit a fourth-order regression
regression1 <- lm(data = schooling_data, 
  earnings ~ poly(schooling, 4, raw=TRUE))
summary(regression1)

# visualize data in a scatter plot with a fourth-order regression
schooling_data %>% 
  ggplot(aes(x = schooling, y = earnings)) + 
  geom_point() + 
  geom_smooth(method = lm, se = TRUE,
              formula = y ~ poly(x, 4, raw=TRUE))

#separate data frame into three groups and append group number
schooling_elem <- schooling_data %>%
  filter(schooling < 6) %>% 
  mutate(group = 1)

schooling_college <- schooling_data %>%
  filter(5 < schooling & schooling < 16) %>% 
  mutate(group = 2)

schooling_post <- schooling_data %>% 
  filter(15 < schooling) %>% 
  mutate(group = 3)

schooling_final <- schooling_elem %>% 
  full_join(schooling_college) %>% 
  full_join(schooling_post)

# fit a segmented regression
# for group 1
regression2 <- lm(data = schooling_elem, earnings ~ schooling)
summary(regression2)

# for group 2 
regression3 <- lm(data = schooling_college, earnings ~ schooling)
summary(regression3)

# for group 3
regression4 <- lm(data = schooling_post, earnings ~ schooling)
summary(regression4)

# plot segmented linear regression
schooling_final %>% 
  ggplot(aes(x = schooling, y = earnings)) + 
  geom_point() + 
  geom_smooth(aes(group = group), method = lm)

# create in and out of sample data
in_sample <- schooling_data %>% 
  filter(schooling < 13)

out_of_sample <- schooling_data %>% 
  filter(12 < schooling)

# fit linear regression to in_sample data 
regression5 <- lm(data = in_sample, earnings ~ schooling)
summary(regression5)

# plot linear regression from in sample data showing out of sample data
ggplot() + 
  geom_point(data = in_sample, 
    aes(x = schooling, y = earnings), color = "green") + 
  geom_point(data = out_of_sample, 
    aes(x = schooling, y = earnings), color = "red") + 
  geom_function(fun = function(x) 0.70967 * x + 11.07127)
  

# fit fourth order regression to in_sample data
regression6 <- lm(data = in_sample, 
  earnings ~ poly(schooling, 4, raw=TRUE))
summary(regression6)

# plot fourth-order regression from in sample data showing out of sample data
ggplot() + 
  geom_point(data = in_sample, 
    aes(x = schooling, y = earnings), color = "green") + 
  geom_point(data = out_of_sample, 
    aes(x = schooling, y = earnings), color = "red") + 
  geom_function(fun = function(x) -0.5514305 * x + 
                  0.2408554 * x^2 + 
                  -0.0185683 * x^3 + 
                  0.0005741 * x^4 +
                  12.6042321)

#separate in_sample data into two groups and append group number
in_sample_g1 <- in_sample %>%
  filter(schooling < 4) %>% 
  mutate(group = 1)

in_sample_g2 <- in_sample %>%
  filter(3 < schooling) %>% 
  mutate(group = 2)

in_sample_segmented <- in_sample_g1 %>% 
  full_join(in_sample_g2) 

# fit a segmented regression to in_sample data
# for group 1
regression7 <- lm(data = in_sample_g1, earnings ~ schooling)
summary(regression7)

# for group 2 
regression8 <- lm(data = in_sample_g2, earnings ~ schooling)
summary(regression8)

# plot segmented linear regression showing out of sample data
ggplot() + 
  geom_point(data = in_sample, 
    aes(x = schooling, y = earnings), color = "green") + 
  geom_point(data = out_of_sample, 
    aes(x = schooling, y = earnings), color = "red") + 
  geom_segment(aes(x = 0, y = 12.41659, xend = 3, yend = 12.45874)) + 
  geom_segment

# calculate average error using a linear and fourth-order regression

# Where to store the square errors for model 1?
errors1 <- c()

# Where to store the square errors for model 2?
errors2 <- c()

# for loop
for (i in c(1:21)){
  
  ### Lets split our data into training and testing
  training <- schooling_data[-i, ]
  testing <- schooling_data[i, ]
  
  ### Model 1
  linear = lm(earnings ~ schooling, data = training)
  temp <- (testing$earnings - predict(linear, testing))^2
  errors1 <- c(errors1, temp)
  
  ### Model 2
  # now re-estimate model 2 with the new training data
  fourth_order = lm(earnings ~ poly(schooling, 4, raw=TRUE), data = training)
  temp <- (testing$earnings - predict(fourth_order, testing))^2
  errors2 <- c(errors2, temp)
  
}

# Now we can see which model has smaller mean squared errors on average
mean(errors1)
mean(errors2)

```
